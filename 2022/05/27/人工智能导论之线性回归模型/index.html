<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="人工智能导论之线性回归模型">
<meta property="og:url" content="http://example.com/2022/05/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="dGlyZWQ&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271529162.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271540544.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271551170.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271559257.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271612213.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271622984.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271627552.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271629824.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271642739.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271643188.png">
<meta property="article:published_time" content="2022-05-27T07:24:31.000Z">
<meta property="article:modified_time" content="2022-05-27T09:03:56.611Z">
<meta property="article:author" content="dglyzwq">
<meta property="article:tag" content="Anaconda">
<meta property="article:tag" content="matplotlib">
<meta property="article:tag" content="JupyterNotebook">
<meta property="article:tag" content="numpy">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271529162.png">

<link rel="canonical" href="http://example.com/2022/05/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>人工智能导论之线性回归模型 | dGlyZWQ's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">dGlyZWQ's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">I'm a Pro, as in Procrastinator.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/DGLYZWQ" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="dglyzwq">
      <meta itemprop="description" content="null">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="dGlyZWQ's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          人工智能导论之线性回归模型
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-05-27 15:24:31 / 修改时间：17:03:56" itemprop="dateCreated datePublished" datetime="2022-05-27T15:24:31+08:00">2022-05-27</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/" itemprop="url" rel="index"><span itemprop="name">人工智能导论</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>9.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>8 分钟</span>
            </span>
            <div class="post-description">一元线性回归、多元线性回归的可视化</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <span id="more"></span>

<h3 id="Numpy实现梯度下降法求解一元线性回归"><a href="#Numpy实现梯度下降法求解一元线性回归" class="headerlink" title="Numpy实现梯度下降法求解一元线性回归"></a>Numpy实现梯度下降法求解一元线性回归</h3><h4 id="基本逻辑"><a href="#基本逻辑" class="headerlink" title="基本逻辑"></a>基本逻辑</h4><p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271529162.png" alt="image-20220527152939125"></p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><h5 id="1-加载样本数据、设置超参数学习率，迭代次数"><a href="#1-加载样本数据、设置超参数学习率，迭代次数" class="headerlink" title="1. 加载样本数据、设置超参数学习率，迭代次数"></a>1. 加载样本数据、设置超参数学习率，迭代次数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 读取波士顿房价数据，前13列为特征，最后一列是target</span></span><br><span class="line">boston_housing = pd.read_csv(<span class="string">&quot;boston_house_prices.csv&quot;</span>, header=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(boston_housing)</span><br><span class="line"><span class="comment"># 转化为Numpy数组</span></span><br><span class="line">housing = np.array(boston_housing)</span><br><span class="line"><span class="comment"># targets为数据中想要预测的目标数据</span></span><br><span class="line">target = housing[:,<span class="number">13</span>]</span><br><span class="line"><span class="comment"># feature为数据中的DIS特征数据的所有值</span></span><br><span class="line">feature = housing[:,<span class="number">7</span>]</span><br><span class="line"><span class="comment"># 切割数据集，训练集占0.8，测试集占0.2</span></span><br><span class="line">split_num = <span class="built_in">int</span>(<span class="built_in">len</span>(feature)*<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">x_train = feature[:split_num]        <span class="comment"># x_train取前80%的数据</span></span><br><span class="line">y_train = feature[:split_num]        <span class="comment"># y_train取前80%的数据</span></span><br><span class="line"></span><br><span class="line">x_test = feature[split_num:]         <span class="comment"># x_test取后20%的数据</span></span><br><span class="line">y_test = feature[split_num:]         <span class="comment"># y_test取后20%的数据</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set:&quot;</span>, <span class="built_in">len</span>(x_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set:&quot;</span>, <span class="built_in">len</span>(x_test))</span><br><span class="line"><span class="comment"># 设置超参数</span></span><br><span class="line">learn_rate = <span class="number">0.01</span>    <span class="comment"># 学习率</span></span><br><span class="line"><span class="built_in">iter</span> = <span class="number">200</span>           <span class="comment"># 迭代次数</span></span><br></pre></td></tr></table></figure>

<p>超参数对于训练非常重要，但在训练之前往往无法确定最佳参数，需要根据经验反复尝试，同时观察算法是否收敛且达到精度。</p>
<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271540544.png" alt="image-20220527154047433"></p>
<h5 id="2-设置模型参数初值、训练模型"><a href="#2-设置模型参数初值、训练模型" class="headerlink" title="2. 设置模型参数初值、训练模型"></a>2. 设置模型参数初值、训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置模型参数初值w,b</span></span><br><span class="line">np.random.seed(<span class="number">612</span>)</span><br><span class="line">w = np.random.randn()   <span class="comment">#randn函数：当参数为空时，随机生成一个数字</span></span><br><span class="line">b = np.random.randn()</span><br><span class="line"><span class="comment"># 创建列表保存每次迭代后的损失值</span></span><br><span class="line">mse_train = []</span><br><span class="line">mse_test = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">iter</span>+<span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 使用均方差损失函数计算损失函数对w和b的偏导数</span></span><br><span class="line">    dL_dw = np.mean(x_train * (w * x_train + b - y_train))</span><br><span class="line">    dL_db = np.mean(w * x_train + b - y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新w,b</span></span><br><span class="line">    w = w - learn_rate * dL_dw</span><br><span class="line">    b = b - learn_rate * dL_db</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用更新后的w和b计算损失，观察是否收敛</span></span><br><span class="line">    pred_train = w * x_train + b</span><br><span class="line">    loss_train = np.mean(np.square(y_train - pred_train))/<span class="number">2</span></span><br><span class="line">    mse_train.append(loss_train)</span><br><span class="line">    </span><br><span class="line">    pred_test = w * x_test + b</span><br><span class="line">    loss_test = np.mean(np.square(y_test - pred_test))/<span class="number">2</span></span><br><span class="line">    mse_test.append(loss_test)</span><br><span class="line">    <span class="comment"># 显示均方误差w的值和b的值</span></span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;i:&#123;&#125;, Train Loss:&#123;&#125;, Test Loss:&#123;&#125;, w:&#123;&#125;, b:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, mse_train[i], mse_test[i], w, b))</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271551170.png" alt="image-20220527155116102"></p>
<p>可以看到，在前10次循环中，训练和测试数据集损失函数下降很陡峭，而后随着迭代次数的增加，损失函数的值趋于稳定。其实在这里差不多迭代到100次就比较收敛了。</p>
<h5 id="3-结果可视化"><a href="#3-结果可视化" class="headerlink" title="3. 结果可视化"></a>3. 结果可视化</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line"><span class="comment"># 绘制子图一</span></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line"><span class="comment"># 绘制DIS属性和房价关系散点图</span></span><br><span class="line">plt.scatter(x_train, y_train, color=<span class="string">&quot;yellow&quot;</span>, label=<span class="string">&quot;data&quot;</span>)</span><br><span class="line"><span class="comment"># 绘制预测模型直线，pred_train是最后一次迭代计算的估计值</span></span><br><span class="line">plt.plot(x_train, pred_train, color=<span class="string">&quot;green&quot;</span>, label=<span class="string">&quot;model&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;DIS&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Price&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制子图二</span></span><br><span class="line"><span class="comment"># 绘制损失变化</span></span><br><span class="line"><span class="comment"># 为了更清楚观察损失变化，使用第20次-200次迭代后的损失数据</span></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">20</span>,<span class="number">200</span>), mse_train[<span class="number">20</span>:<span class="number">200</span>], color=<span class="string">&quot;yellow&quot;</span>, lw=<span class="number">3</span>, label=<span class="string">&quot;train_loss&quot;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">20</span>,<span class="number">200</span>), mse_test[<span class="number">20</span>:<span class="number">200</span>], color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">1.5</span>, label=<span class="string">&quot;test_loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Iteration&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制子图三</span></span><br><span class="line"><span class="comment"># 展示预测值与实际值之间的差距</span></span><br><span class="line"><span class="comment"># 实际房价和预测房价点线图</span></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(y_train, color=<span class="string">&quot;yellow&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, label=<span class="string">&quot;true_price&quot;</span>)</span><br><span class="line">plt.plot(pred_train, color=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&quot;+&quot;</span>, label=<span class="string">&quot;predict&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Samples&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Price&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制子图4</span></span><br><span class="line"><span class="comment"># 展示真实房价与预测房价之间的差距</span></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(y_test, color=<span class="string">&quot;yellow&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, label=<span class="string">&quot;true_price&quot;</span>)</span><br><span class="line">plt.plot(pred_test, color=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&quot;+&quot;</span>, label=<span class="string">&quot;predict&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Samples&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Price&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271559257.png" alt="image-20220527155940186"></p>
<p>可视化结果如上图，可以看出，DIS属性与房价预测之间的关系。</p>
<h4 id="使用解析法与梯度下降法计算一元线性回归模型的精确解并可视化"><a href="#使用解析法与梯度下降法计算一元线性回归模型的精确解并可视化" class="headerlink" title="使用解析法与梯度下降法计算一元线性回归模型的精确解并可视化"></a>使用解析法与梯度下降法计算一元线性回归模型的精确解并可视化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">boston_housing = pd.read_csv(<span class="string">&quot;boston_house_prices.csv&quot;</span>, header=<span class="number">0</span>)</span><br><span class="line">housing = np.array(boston_housing)</span><br><span class="line">target = housing[:,<span class="number">13</span>]</span><br><span class="line">feature = housing[:,<span class="number">7</span>]</span><br><span class="line">split_num = <span class="built_in">int</span>(<span class="built_in">len</span>(feature)*<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析法</span></span><br><span class="line">x = housing[:,<span class="number">7</span>]</span><br><span class="line">y = housing[:,<span class="number">13</span>]</span><br><span class="line">meanX = np.mean(x)</span><br><span class="line">meanY = np.mean(y)</span><br><span class="line"></span><br><span class="line">sumXY = np.<span class="built_in">sum</span>((x - meanX)*(y - meanY))</span><br><span class="line">sumX = np.<span class="built_in">sum</span>((x - meanX)*(x - meanY))</span><br><span class="line"></span><br><span class="line">w = sumXY/sumX</span><br><span class="line">b = meanY-w*meanX</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;权值w=&quot;</span>,w,<span class="string">&quot;\n偏置值b=&quot;</span>,b)</span><br><span class="line"></span><br><span class="line">x_test= housing[:,<span class="number">7</span>]</span><br><span class="line">y_pred = (w*x_test+b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降法</span></span><br><span class="line">x_train = feature[:split_num]</span><br><span class="line">y_train = feature[:split_num]</span><br><span class="line">x_test1 = feature[split_num:]</span><br><span class="line">y_test1 = feature[split_num:]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set:&quot;</span>, <span class="built_in">len</span>(x_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set:&quot;</span>, <span class="built_in">len</span>(x_test1))</span><br><span class="line">learn_rate = <span class="number">0.05</span></span><br><span class="line"><span class="built_in">iter</span> = <span class="number">200</span></span><br><span class="line">np.random.seed(<span class="number">612</span>)</span><br><span class="line">w1 = np.random.randn()</span><br><span class="line">b1 = np.random.randn()</span><br><span class="line">mse_train = []</span><br><span class="line">mse_test = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">iter</span>+<span class="number">1</span>):</span><br><span class="line">    dL_dw = np.mean(x_train * (w1 * x_train + b1 - y_train))</span><br><span class="line">    dL_db = np.mean(w1 * x_train + b1 - y_train)   </span><br><span class="line">    w1 = w1 - learn_rate * dL_dw</span><br><span class="line">    b1 = b1 - learn_rate * dL_db    </span><br><span class="line">    pred_train = w1 * x_train + b1</span><br><span class="line">    </span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(x,y,color=<span class="string">&quot;blue&quot;</span>,label=<span class="string">&quot;实际房价&quot;</span>)</span><br><span class="line">plt.plot(x_test,y_pred,color=<span class="string">&quot;green&quot;</span>,label=<span class="string">&quot;解析法&quot;</span>)</span><br><span class="line">plt.plot(x_train, pred_train, color=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;梯度下降法&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;DIS&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Price&quot;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>

<p>可视化结果如下图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271612213.png" alt="image-20220527161256160"></p>
<h3 id="Numpy实现梯度下降法求解多元线性回归"><a href="#Numpy实现梯度下降法求解多元线性回归" class="headerlink" title="Numpy实现梯度下降法求解多元线性回归"></a>Numpy实现梯度下降法求解多元线性回归</h3><p>选择波士顿房价数据集中的任意两个属性作为输入X数据，选择房价作为Y数据，构建多元线性回归模型。</p>
<p>注意：若两个属性之间差异较大，需要对属性数据进行<strong>规范化</strong>。</p>
<h4 id="规范化"><a href="#规范化" class="headerlink" title="规范化"></a>规范化</h4><ul>
<li>标准化：通过减去均值然后除以方差（或标准差），将数据按比例缩放，使之落入一个较小的特定区间。</li>
<li>特征缩放：将属性缩放到一个指定的最大和最小值（通常是1-0）之间。</li>
<li>归一化：将某一属性特征的模转化成1。</li>
</ul>
<p>例如，对波士顿房价数据集中feature中的属性RM进行特征缩放，可以使用numpy直接完成：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x1 = (feature[:,<span class="number">5</span>] - feature[:,<span class="number">5</span>].<span class="built_in">min</span>())/(feature[:,<span class="number">5</span>].<span class="built_in">max</span>() - feature[:,<span class="number">5</span>].<span class="built_in">min</span>())</span><br></pre></td></tr></table></figure>

<h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><h5 id="1-加载样本数据，数据归一化处理"><a href="#1-加载样本数据，数据归一化处理" class="headerlink" title="1. 加载样本数据，数据归一化处理"></a>1. 加载样本数据，数据归一化处理</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">boston_housing = pd.read_csv(<span class="string">&quot;boston_house_prices.csv&quot;</span>, header=<span class="number">0</span>)</span><br><span class="line">housing = np.array(boston_housing)</span><br><span class="line">RAD = housing[:,<span class="number">8</span>]</span><br><span class="line">TAX = housing[:,<span class="number">9</span>]</span><br><span class="line">price = housing[:,<span class="number">13</span>]</span><br><span class="line">num = <span class="built_in">len</span>(RAD)</span><br><span class="line">x0 = np.ones(num)</span><br><span class="line">x1 = (RAD - RAD.<span class="built_in">min</span>()) / (RAD.<span class="built_in">max</span>() - RAD.<span class="built_in">min</span>())</span><br><span class="line">x2 = (TAX - TAX.<span class="built_in">min</span>()) / (TAX.<span class="built_in">max</span>() - TAX.<span class="built_in">min</span>())</span><br><span class="line"></span><br><span class="line">X = np.stack((x0,x1,x2), axis=<span class="number">1</span>)</span><br><span class="line">Y = price.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(X.shape, Y.shape)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271622984.png" alt="image-20220527162242949"></p>
<p>返回值可以得到X是一个506行3列的二维数组，Y是一个506行1列的二维数组</p>
<h5 id="2-设置超参数，训练模型"><a href="#2-设置超参数，训练模型" class="headerlink" title="2. 设置超参数，训练模型"></a>2. 设置超参数，训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">learn_rate = <span class="number">0.001</span>         <span class="comment"># 学习率</span></span><br><span class="line"><span class="built_in">iter</span> = <span class="number">200</span>                 <span class="comment"># 迭代次数</span></span><br><span class="line">display_step = <span class="number">10</span>          <span class="comment"># 每10次显示</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">612</span>)</span><br><span class="line">W = np.random.randn(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">mse = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">iter</span>+<span class="number">1</span>):</span><br><span class="line">    dl_dW = np.matmul(np.transpose(X),np.matmul(X,W)-Y)</span><br><span class="line">    W = W - learn_rate * dl_dW</span><br><span class="line">    PRED = np.matmul(X,W)</span><br><span class="line">    Loss = np.mean(np.square(Y - PRED))/<span class="number">2</span></span><br><span class="line">    mse.append(Loss)</span><br><span class="line">    <span class="keyword">if</span> i % display_step == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;i:%i,Loss: %f&quot;</span> % (i,mse[i]))</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271627552.png" alt="image-20220527162702512"></p>
<p>可以看到，损失函数下降曲线在前10次最陡峭。</p>
<h5 id="3-绘制损失函数下降曲线以及预测值和实际值之间的差异曲线图"><a href="#3-绘制损失函数下降曲线以及预测值和实际值之间的差异曲线图" class="headerlink" title="3. 绘制损失函数下降曲线以及预测值和实际值之间的差异曲线图"></a>3. 绘制损失函数下降曲线以及预测值和实际值之间的差异曲线图</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(mse)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Iteration&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">PRED = PRED.reshape(-<span class="number">1</span>)</span><br><span class="line">plt.plot(price,color=<span class="string">&quot;yellow&quot;</span>,marker=<span class="string">&quot;o&quot;</span>,label=<span class="string">&quot;实际房价&quot;</span>)</span><br><span class="line">plt.plot(PRED, color=<span class="string">&quot;green&quot;</span>,marker=<span class="string">&#x27;.&#x27;</span>,label=<span class="string">&quot;预测房价&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Sample&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Price&quot;</span>,fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271629824.png" alt="image-20220527162917775"></p>
<h3 id="Pytorch实现梯度下降法求解多元线性回归"><a href="#Pytorch实现梯度下降法求解多元线性回归" class="headerlink" title="Pytorch实现梯度下降法求解多元线性回归"></a>Pytorch实现梯度下降法求解多元线性回归</h3><h4 id="报错解决：No-module-name-‘torch’"><a href="#报错解决：No-module-name-‘torch’" class="headerlink" title="报错解决：No module name ‘torch’"></a>报错解决：No module name ‘torch’</h4><p>进入Anaconda Prompt，输入以下代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate pytorch</span><br></pre></td></tr></table></figure>

<p>进入pytorch环境后，安装ipython和jupyter（这一步也可以用pip安装）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install ipython</span><br><span class="line">conda install jupyter</span><br></pre></td></tr></table></figure>

<p>安装完成后在当前环境下继续输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>

<p>直接打开jupyter notebook，现在可以成功import torch了</p>
<h4 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h4><h5 id="1-加载数据集、构建神经网络模型"><a href="#1-加载数据集、构建神经网络模型" class="headerlink" title="1. 加载数据集、构建神经网络模型"></a>1. 加载数据集、构建神经网络模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn,optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">boston_housing = pd.read_csv(<span class="string">&quot;boston_house_prices.csv&quot;</span>, header=<span class="number">0</span>)</span><br><span class="line">housing = np.array(boston_housing)</span><br><span class="line">targets = housing[:,<span class="number">13</span>]</span><br><span class="line">features = housing[:, :<span class="number">13</span>]</span><br><span class="line">split_num = <span class="built_in">int</span>(<span class="built_in">len</span>(features)*<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建神经网络模型，继承pytorch神经网络类</span></span><br><span class="line"><span class="comment"># 在pytorch定义网络类有固定格式，pytorch可以自动计算梯度，可以不用自定义误差反向传播算法</span></span><br><span class="line"><span class="comment"># 一般把网络中具有可学习参数的层放在__init__函数中</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line">    <span class="comment"># 定义网络结构</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化父类nn.Module，固定操作</span></span><br><span class="line">        <span class="built_in">super</span>(LinearRegression, self).__init__()</span><br><span class="line">        self.fc = nn.Linear(<span class="number">13</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 定义前向网络计算    </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.fc(x)</span><br></pre></td></tr></table></figure>

<h5 id="2-实例化模型，处理数据，设置超参数"><a href="#2-实例化模型，处理数据，设置超参数" class="headerlink" title="2. 实例化模型，处理数据，设置超参数"></a>2. 实例化模型，处理数据，设置超参数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model = LinearRegression()</span><br><span class="line"><span class="comment"># features数据标准化，targets用unsqueeze整理维度到一维</span></span><br><span class="line">features = (features - features.mean(axis=<span class="number">0</span>))/features.std(axis=<span class="number">0</span>)</span><br><span class="line">x_data, y_data = torch.FloatTensor(features), torch.unsqueeze(torch.FloatTensor(targets), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切割数据集</span></span><br><span class="line">x_train, y_train = x_data[<span class="number">0</span>:split_num, :], y_data[<span class="number">0</span>:split_num]</span><br><span class="line">inputs_train = Variable(x_train)</span><br><span class="line">target_train = Variable(y_train)</span><br><span class="line">x_test, y_test = x_data[split_num:, :], y_data[split_num:]</span><br><span class="line">inputs_test = Variable(x_test)</span><br><span class="line">target_test = Variable(y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置超参数</span></span><br><span class="line">epochs = <span class="number">3000</span></span><br><span class="line">learning_rate = <span class="number">0.05</span></span><br></pre></td></tr></table></figure>

<h5 id="3-定义损失函数和优化器、定义参数重置函数"><a href="#3-定义损失函数和优化器、定义参数重置函数" class="headerlink" title="3. 定义损失函数和优化器、定义参数重置函数"></a>3. 定义损失函数和优化器、定义参数重置函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义损失函数，先使用最简单的均方差代价函数</span></span><br><span class="line">loss_func = nn.MSELoss()</span><br><span class="line"><span class="comment"># 定义优化器，随机梯度下降法，学习率0.01</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr = learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义参数重置函数，保证每次重新执行for循环时从零开始训练</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weight_reset</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d) <span class="keyword">or</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">        m.reset_parameters()</span><br></pre></td></tr></table></figure>

<h5 id="4-训练模型"><a href="#4-训练模型" class="headerlink" title="4. 训练模型"></a>4. 训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">mse_train = []</span><br><span class="line">mse_test = []</span><br><span class="line">model.apply(weight_reset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># 计算模型输出结果</span></span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    pred_train = model(inputs_train)</span><br><span class="line">    loss_train = loss_func(pred_train, target_train)</span><br><span class="line">    </span><br><span class="line">    pred_test = model(inputs_test)</span><br><span class="line">    loss_test = loss_func(pred_test, target_test)</span><br><span class="line">    </span><br><span class="line">    mse_train.append(loss_train.item())</span><br><span class="line">    mse_test.append(loss_test.item())</span><br><span class="line">    <span class="comment"># 梯度清零</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># 反向传播，计算参数</span></span><br><span class="line">    loss_train.backward()</span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;epoch:&#123;&#125;, train_loss:&#123;&#125;, test_loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i,loss_train.item(),loss_test.item()), sep=<span class="string">&#x27;\t&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271642739.png" alt="image-20220527164239621"></p>
<p>迭代过程如上图</p>
<h5 id="5-可视化模型及结果"><a href="#5-可视化模型及结果" class="headerlink" title="5. 可视化模型及结果"></a>5. 可视化模型及结果</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化Loss下降曲线</span></span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;MSE&quot;</span>)</span><br><span class="line">plt.plot(mse_train, color=<span class="string">&quot;yellow&quot;</span>, lw=<span class="number">3</span>)</span><br><span class="line">plt.plot(mse_test, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化预测结果和训练数据集</span></span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">plt.plot(y_train, color=<span class="string">&quot;yellow&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, label=<span class="string">&quot;true_price&quot;</span>)</span><br><span class="line">plt.plot(pred_train.data.numpy(), color=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&quot;.&quot;</span>, label=<span class="string">&quot;predict&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.ylabel(<span class="string">&quot;Price&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化预测结果和测试数据集</span></span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">plt.plot(y_test, color=<span class="string">&quot;yellow&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, label=<span class="string">&quot;true_price&quot;</span>)</span><br><span class="line">plt.plot(pred_test.data.numpy(), color=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&quot;.&quot;</span>, label=<span class="string">&quot;predict&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.ylabel(<span class="string">&quot;Price&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/dglyzwq/PicGo/img/202205271643188.png" alt="image-20220527164346135"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Anaconda/" rel="tag"># Anaconda</a>
              <a href="/tags/matplotlib/" rel="tag"># matplotlib</a>
              <a href="/tags/JupyterNotebook/" rel="tag"># JupyterNotebook</a>
              <a href="/tags/numpy/" rel="tag"># numpy</a>
              <a href="/tags/pytorch/" rel="tag"># pytorch</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/05/25/Postman%E4%B9%8B%E7%BC%96%E5%86%99%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/" rel="prev" title="Postman之编写接口测试框架">
      <i class="fa fa-chevron-left"></i> Postman之编写接口测试框架
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Numpy%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%B1%82%E8%A7%A3%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.</span> <span class="nav-text">Numpy实现梯度下降法求解一元线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E9%80%BB%E8%BE%91"><span class="nav-number">1.1.</span> <span class="nav-text">基本逻辑</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.2.</span> <span class="nav-text">代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E5%8A%A0%E8%BD%BD%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E3%80%81%E8%AE%BE%E7%BD%AE%E8%B6%85%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%8C%E8%BF%AD%E4%BB%A3%E6%AC%A1%E6%95%B0"><span class="nav-number">1.2.1.</span> <span class="nav-text">1. 加载样本数据、设置超参数学习率，迭代次数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%88%9D%E5%80%BC%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.2.</span> <span class="nav-text">2. 设置模型参数初值、训练模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">1.2.3.</span> <span class="nav-text">3. 结果可视化</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E8%A7%A3%E6%9E%90%E6%B3%95%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E8%AE%A1%E7%AE%97%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%B2%BE%E7%A1%AE%E8%A7%A3%E5%B9%B6%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">1.3.</span> <span class="nav-text">使用解析法与梯度下降法计算一元线性回归模型的精确解并可视化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Numpy%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%B1%82%E8%A7%A3%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">2.</span> <span class="nav-text">Numpy实现梯度下降法求解多元线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%84%E8%8C%83%E5%8C%96"><span class="nav-number">2.1.</span> <span class="nav-text">规范化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-1"><span class="nav-number">2.2.</span> <span class="nav-text">代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E5%8A%A0%E8%BD%BD%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="nav-number">2.2.1.</span> <span class="nav-text">1. 加载样本数据，数据归一化处理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E8%AE%BE%E7%BD%AE%E8%B6%85%E5%8F%82%E6%95%B0%EF%BC%8C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.2.2.</span> <span class="nav-text">2. 设置超参数，训练模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E7%BB%98%E5%88%B6%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8B%E9%99%8D%E6%9B%B2%E7%BA%BF%E4%BB%A5%E5%8F%8A%E9%A2%84%E6%B5%8B%E5%80%BC%E5%92%8C%E5%AE%9E%E9%99%85%E5%80%BC%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B7%AE%E5%BC%82%E6%9B%B2%E7%BA%BF%E5%9B%BE"><span class="nav-number">2.2.3.</span> <span class="nav-text">3. 绘制损失函数下降曲线以及预测值和实际值之间的差异曲线图</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pytorch%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%B1%82%E8%A7%A3%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">3.</span> <span class="nav-text">Pytorch实现梯度下降法求解多元线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%EF%BC%9ANo-module-name-%E2%80%98torch%E2%80%99"><span class="nav-number">3.1.</span> <span class="nav-text">报错解决：No module name ‘torch’</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-2"><span class="nav-number">3.2.</span> <span class="nav-text">代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86%E3%80%81%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.1.</span> <span class="nav-text">1. 加载数据集、构建神经网络模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%EF%BC%8C%E8%AE%BE%E7%BD%AE%E8%B6%85%E5%8F%82%E6%95%B0"><span class="nav-number">3.2.2.</span> <span class="nav-text">2. 实例化模型，处理数据，设置超参数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8%E3%80%81%E5%AE%9A%E4%B9%89%E5%8F%82%E6%95%B0%E9%87%8D%E7%BD%AE%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.3.</span> <span class="nav-text">3. 定义损失函数和优化器、定义参数重置函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.4.</span> <span class="nav-text">4. 训练模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-%E5%8F%AF%E8%A7%86%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%8A%E7%BB%93%E6%9E%9C"><span class="nav-number">3.2.5.</span> <span class="nav-text">5. 可视化模型及结果</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="dglyzwq"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">dglyzwq</p>
  <div class="site-description" itemprop="description">null</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/DGLYZWQ" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;DGLYZWQ" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:18867979070@163.com" title="E-Mail → mailto:18867979070@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://plus.google.com/" title="Google → https:&#x2F;&#x2F;plus.google.com" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>Google</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">dglyzwq</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">47k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">43 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
